{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USPTO data ingress\n",
    "\n",
    "Data found at https://bulkdata.uspto.gov/. According to the terms and conditions, there is no restriction on use. In this notebook we want to evaluate the suitability of the data, and if so, download and clean.\n",
    "\n",
    "There are a number of different versions of the dataset. \n",
    "\n",
    "- Patent Grant Bibliographic (Front Page) Text Data (JAN 1976 - PRESENT): sample file is approximately 18MB. We downloaded this in the hope that it would contain a substantial amount of text, but this is not the case. It contains titles and metadata about the patents, but nothing comparable to an abstract.\n",
    "\n",
    "- Patent Grant Full Text Data (No Images) (JAN 1976 - PRESENT): sample file is approximately 800MB. Too large to investigate in Notebook++, so we investigate it here instead using Elementtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from xml.dom import minidom\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "junk after document element: line 899, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\emmat\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2963\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-2-6bf7e7700356>\"\u001b[0m, line \u001b[0;32m1\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    tree = ET.parse('../../Data/uspto_sample/ipg210105.xml')\n",
      "  File \u001b[0;32m\"C:\\Users\\emmat\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[0m, line \u001b[0;32m1196\u001b[0m, in \u001b[0;35mparse\u001b[0m\n    tree.parse(source, parser)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\emmat\\Anaconda3\\lib\\xml\\etree\\ElementTree.py\"\u001b[1;36m, line \u001b[1;32m597\u001b[1;36m, in \u001b[1;35mparse\u001b[1;36m\u001b[0m\n\u001b[1;33m    self._root = parser._parse_whole(source)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"<string>\"\u001b[1;36m, line \u001b[1;32munknown\u001b[0m\n\u001b[1;31mParseError\u001b[0m\u001b[1;31m:\u001b[0m junk after document element: line 899, column 0\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse('../../Data/uspto_sample/ipg210105.xml')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay there is an issue with the form of the XML file?\n",
    "\n",
    "From investigation, there is no root node. It seems like many XML files have been smushed together. They each start with\n",
    "```<!DOCTYPE us-patent-grant SYSTEM \"us-patent-grant-v45-2014-04-03.dtd\" [ ]>``` (or similar)\n",
    "\n",
    "```\n",
    "<!DOCTYPE...>\n",
    "    <us-patent grant... date-produced=\"20201221\">\n",
    "\n",
    "    <description-of-drawings>\n",
    "\n",
    "        <p id=\"p-0001\" num=\"0001\"><figref idref=\"DRAWINGS\">FIG. 1</figref> is a top, front perspective view of a molded tortilla pocket according to our new design;</p>\n",
    "        \n",
    "    <claim-text>The ornamental design for a molded tortilla pocket, as shown and described.</claim-text>\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6438\n"
     ]
    }
   ],
   "source": [
    "with io.open(\"../../Data/uspto_sample/ipg210309.xml\", 'r', encoding='utf-8-sig') as f:\n",
    "    xml = f.read()\n",
    "    \n",
    "xml = re.sub(r'<!DOCTYPE .+>\\n', '', xml)\n",
    "xml = re.sub(r'<!DOCTYPE .+>', '', xml)\n",
    "xml = re.sub(r'<\\?xml version=\"1.0\" encoding=\"UTF-8\"\\?>\\n', '', xml)\n",
    "xml = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root>' + xml + '</root>'\n",
    "\n",
    "tree = ET.fromstring(xml)\n",
    "print(len(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'us-bibliographic-data-grant' at 0x00000288526E4278>\n",
      "<Element 'abstract' at 0x00000288527AC728>\n",
      "<Element 'drawings' at 0x00000288527AC7C8>\n",
      "<Element 'description' at 0x00000288527B11D8>\n",
      "<Element 'us-claim-statement' at 0x00000288527E82C8>\n",
      "<Element 'claims' at 0x00000288527E8318>\n"
     ]
    }
   ],
   "source": [
    "root = tree[900]\n",
    "for child in root:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_document(root):\n",
    "    title = ''\n",
    "    abstract = ''\n",
    "    description = ''\n",
    "    claims = ''\n",
    "    ipcr_classifications = []\n",
    "    cpc_classifications = []\n",
    "    doc_number = ''\n",
    "    date = ''\n",
    "    \n",
    "    if root.find('us-bibliographic-data-grant') is None:\n",
    "        # unsuitable for lack of data!\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        ipcr_clfs = root.find('us-bibliographic-data-grant').find('classifications-ipcr')\n",
    "        if ipcr_clfs is not None:\n",
    "            for clf in ipcr_clfs:\n",
    "                ipcr_classifications.append({\n",
    "                    'section': clf.find('section').text,\n",
    "                    'class': clf.find('class').text,\n",
    "                    'subclass': clf.find('subclass').text,\n",
    "                    'main_group': clf.find('main-group').text,\n",
    "                    'subgroup': clf.find('subgroup').text,\n",
    "                    'date': clf.find('ipc-version-indicator').find('date').text\n",
    "                })\n",
    "\n",
    "        if root.find('us-bibliographic-data-grant').find('classifications-cpc') is not None:\n",
    "            cpc_clfs = root.find('us-bibliographic-data-grant').find('classifications-cpc').find('main-cpc').findall('classification-cpc')\n",
    "\n",
    "            if root.find('us-bibliographic-data-grant').find('classifications-cpc').find('further-cpc') is not None:\n",
    "                cpc_clfs += root.find('us-bibliographic-data-grant').find('classifications-cpc').find('further-cpc').findall('classification-cpc')\n",
    "\n",
    "            if len(cpc_clfs) > 0:\n",
    "                for clf in cpc_clfs:\n",
    "                    cpc_classifications.append({\n",
    "                        'section': clf.find('section').text,\n",
    "                        'class': clf.find('class').text,\n",
    "                        'subclass': clf.find('subclass').text,\n",
    "                        'main_group': clf.find('main-group').text,\n",
    "                        'subgroup': clf.find('subgroup').text,\n",
    "                        'date': clf.find('cpc-version-indicator').find('date').text\n",
    "                    })\n",
    "        \n",
    "        clf_sections = [c['section'] for c in ipcr_classifications+cpc_classifications]\n",
    "        \n",
    "        if 'G' in clf_sections or 'H' in clf_sections or 'Y' in clf_sections:\n",
    "            doc_number = root.find('us-bibliographic-data-grant').find('application-reference').find('document-id').find('doc-number').text\n",
    "            date_produced = root.attrib['date-produced']\n",
    "            date_published = root.attrib['date-produced']\n",
    "            date_filed = root.find('us-bibliographic-data-grant').find('application-reference').find('document-id').find('date').text\n",
    "            date = date_filed[0:6]\n",
    "            \n",
    "            if date == '':\n",
    "                # unsuitable for lacking date!\n",
    "                return 2\n",
    "\n",
    "            title = root.find('us-bibliographic-data-grant').find('invention-title').text\n",
    "            \n",
    "            if title == '':\n",
    "                # unsuitable for lacking title!\n",
    "                return 3\n",
    "\n",
    "            text_abstract = root.find('abstract')\n",
    "            if text_abstract is not None:\n",
    "                for child in text_abstract:\n",
    "                    if type(child.text) == str:\n",
    "                        abstract += child.text + ' '\n",
    "                    if type(child.tail) == str:\n",
    "                        abstract += child.tail + ' '\n",
    "\n",
    "                    for grandchild in child:\n",
    "                        if type(grandchild.text) == str:\n",
    "                            abstract += grandchild.text + ' '\n",
    "                        if type(grandchild.tail) == str:\n",
    "                            abstract += grandchild.tail + ' '  \n",
    "                \n",
    "                \n",
    "            text_description = root.find('description')\n",
    "            if text_description is not None:\n",
    "                for child in text_description:\n",
    "                    if type(child.text) == str:\n",
    "                        description += child.text + ' '\n",
    "                    if type(child.tail) == str:\n",
    "                        description += child.tail + ' '\n",
    "\n",
    "            all_claims = root.find('claims').findall('claim')\n",
    "            if len(all_claims) > 0:\n",
    "                for claim in all_claims:\n",
    "                    claim_texts = claim.find('claim-text')\n",
    "                    for child in claim_texts:\n",
    "                        if type(child.text) == str:\n",
    "                            claims += child.text + ' '\n",
    "                        if type(child.tail) == str:\n",
    "                            claims += child.tail + ' '\n",
    "                            \n",
    "            if len(abstract + description + claims) < 50:\n",
    "                # unsuitable for lack of text!\n",
    "                return 4\n",
    "\n",
    "            json_document = {\n",
    "                'year_month': date,\n",
    "                'doc_number': doc_number,\n",
    "                'date_filed': date_filed,\n",
    "                'date_produced': date_produced,\n",
    "                'date_published': date_published,\n",
    "                'title': title,\n",
    "                'abstract': abstract,\n",
    "                'description': description,\n",
    "                'claims': claims,\n",
    "                'ipcr_classifications': ipcr_classifications,\n",
    "                'cpc_classifications': cpc_classifications\n",
    "            }\n",
    "\n",
    "            return json_document\n",
    "        \n",
    "        else:\n",
    "            # Unsuitable because does not have a classification linked to computer science\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_document_legacy(root):\n",
    "    '''\n",
    "    This concerns documents from 2005 and prior years\n",
    "    '''\n",
    "    title = ''\n",
    "    abstract = ''\n",
    "    description = ''\n",
    "    claims = ''\n",
    "    ipcr_classifications = []\n",
    "    cpc_classifications = []\n",
    "    us_classifications = []\n",
    "    doc_number = ''\n",
    "    date = ''\n",
    "    \n",
    "    if root.find('us-bibliographic-data-grant') is None:\n",
    "        # unsuitable for lack of data!\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        if root.find('us-bibliographic-data-grant').find('classification-national') is not None:\n",
    "            us_classifications.append(root.find('us-bibliographic-data-grant').find('classification-national').find('main-classification').text)\n",
    "            \n",
    "            for clf in root.find('us-bibliographic-data-grant').find('classification-national').findall('further-classification'):\n",
    "                us_classifications.append(clf.text)\n",
    "            \n",
    "            doc_number = root.find('us-bibliographic-data-grant').find('application-reference').find('document-id').find('doc-number').text\n",
    "            date_produced = root.attrib['date-produced']\n",
    "            date_published = root.attrib['date-produced']\n",
    "            date_filed = root.find('us-bibliographic-data-grant').find('application-reference').find('document-id').find('date').text\n",
    "            date = date_filed[0:6]\n",
    "            \n",
    "            if date == '':\n",
    "                # unsuitable for lacking date!\n",
    "                return 2\n",
    "\n",
    "            title = root.find('us-bibliographic-data-grant').find('invention-title').text\n",
    "            \n",
    "            if title == '':\n",
    "                # unsuitable for lacking title!\n",
    "                return 3\n",
    "\n",
    "            text_abstract = root.find('abstract')\n",
    "            if text_abstract is not None:\n",
    "                for child in text_abstract:\n",
    "                    if type(child.text) == str:\n",
    "                        abstract += child.text + ' '\n",
    "                    if type(child.tail) == str:\n",
    "                        abstract += child.tail + ' '\n",
    "\n",
    "                    for grandchild in child:\n",
    "                        if type(grandchild.text) == str:\n",
    "                            abstract += grandchild.text + ' '\n",
    "                        if type(grandchild.tail) == str:\n",
    "                            abstract += grandchild.tail + ' '  \n",
    "                \n",
    "                \n",
    "            text_description = root.find('description')\n",
    "            if text_description is not None:\n",
    "                for child in text_description:\n",
    "                    if type(child.text) == str:\n",
    "                        description += child.text + ' '\n",
    "                    if type(child.tail) == str:\n",
    "                        description += child.tail + ' '\n",
    "\n",
    "            all_claims = root.find('claims').findall('claim')\n",
    "            if len(all_claims) > 0:\n",
    "                for claim in all_claims:\n",
    "                    claim_texts = claim.find('claim-text')\n",
    "                    for child in claim_texts:\n",
    "                        if type(child.text) == str:\n",
    "                            claims += child.text + ' '\n",
    "                        if type(child.tail) == str:\n",
    "                            claims += child.tail + ' '\n",
    "                            \n",
    "            if len(abstract + description + claims) < 50:\n",
    "                # unsuitable for lack of text!\n",
    "                return 4\n",
    "\n",
    "            json_document = {\n",
    "                'year_month': date,\n",
    "                'doc_number': doc_number,\n",
    "                'date_filed': date_filed,\n",
    "                'date_produced': date_produced,\n",
    "                'date_published': date_published,\n",
    "                'title': title,\n",
    "                'abstract': abstract,\n",
    "                'description': description,\n",
    "                'claims': claims,\n",
    "                'ipcr_classifications': ipcr_classifications,\n",
    "                'cpc_classifications': cpc_classifications,\n",
    "                'us_classifications': us_classifications\n",
    "            }\n",
    "\n",
    "            return json_document\n",
    "        \n",
    "        else:\n",
    "            # Unsuitable because does not have a classification linked to computer science\n",
    "            return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipg210112.xml 32.59398865699768\n",
      "ipg210119.xml 20.598675966262817\n",
      "ipg210202.xml 45.26545000076294\n",
      "ipg210209.xml 28.660041093826294\n",
      "ipg210216.xml 44.08662819862366\n",
      "ipg210223.xml 40.08888030052185\n",
      "ipg210302.xml 37.50640106201172\n",
      "ipg210309.xml 33.001054763793945\n",
      "ipg210316.xml 41.39901828765869\n",
      "ipg210323.xml 48.35028338432312\n",
      "Irregular format:  1558\n",
      "Wrong classification:  26417\n",
      "No date:  0\n",
      "No title:  0\n",
      "Short text:  9\n",
      "Success:  43715\n"
     ]
    }
   ],
   "source": [
    "outcome = defaultdict(int)\n",
    "for year in np.range(2006, 2021):\n",
    "    files = os.listdir('D:/uspto/'+str(year))\n",
    "    outcome['year'] = year\n",
    "    for file in files:\n",
    "        if file[-3:] == 'xml':\n",
    "            time0 = time.time()\n",
    "\n",
    "            with io.open('D:/uspto/'+str(year)+'/'+file, 'r', encoding='utf-8-sig') as f:\n",
    "                xml = f.read()\n",
    "\n",
    "                xml = re.sub(r'<!DOCTYPE .+>\\n', '', xml)\n",
    "                xml = re.sub(r'<!DOCTYPE .+>', '', xml)\n",
    "                xml = re.sub(r'<\\?xml version=\"1.0\" encoding=\"UTF-8\"\\?>\\n', '', xml)\n",
    "                xml = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><root>' + xml + '</root>'\n",
    "\n",
    "            tree = ET.fromstring(xml)\n",
    "            del xml\n",
    "\n",
    "            documents = defaultdict(list)\n",
    "            for i, root in enumerate(tree):\n",
    "                document = make_document(root)\n",
    "                if type(document) != int:\n",
    "                    documents[document['year_month']].append(document)\n",
    "                    outcome[5]+=1\n",
    "                else:\n",
    "                    outcome[document]+=1\n",
    "\n",
    "\n",
    "            del tree\n",
    "\n",
    "            for year_filed in documents.keys():\n",
    "\n",
    "                with open('../../Data/uspto_filtered/'+year_filed+'.txt', \"a\") as f:\n",
    "                    for document in documents[year_filed]:\n",
    "                        f.write(json.dumps(document)+'\\n')\n",
    "\n",
    "            del documents\n",
    "\n",
    "            print(file, time.time()-time0)\n",
    "    print(year)\n",
    "    print('Irregular format: ', outcome[0])\n",
    "    print('Wrong classification: ', outcome[1])\n",
    "    print('No date: ', outcome[2])\n",
    "    print('No title: ', outcome[3])\n",
    "    print('Short text: ', outcome[4])\n",
    "    print('Success: ', outcome[5])\n",
    "\n",
    "with open('../../Data/uspto_filtered/outcomes.txt', \"a\") as f:\n",
    "    f.write(json.dumps(outcome)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'year': 2010, 1: 108664, 5: 135935, 0: 5951, 2: 0, 3: 0, 4: 0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
